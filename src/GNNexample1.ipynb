{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GNNexample1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeHOzjuvpAwo",
        "outputId": "09e56733-7b55-442d-b9f6-c74877aaafda"
      },
      "source": [
        "pip install torch_sparse"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch_sparse\n",
            "  Downloading https://files.pythonhosted.org/packages/3c/dd/f34dce6512a3922948c3ac0cf50cceb2eeafeedd34a278d502eb77d07dc0/torch_sparse-0.6.8.tar.gz\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch_sparse) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy->torch_sparse) (1.19.5)\n",
            "Building wheels for collected packages: torch-sparse\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-sparse: filename=torch_sparse-0.6.8-cp36-cp36m-linux_x86_64.whl size=22582506 sha256=79d0ef679e44fc37e00c952481c091d122defe5d1468f7790ee9ba2fdc16fa80\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/d3/94/e2560941994bebe665b1dccc69faf33d33aeee2bca353c9bcc\n",
            "Successfully built torch-sparse\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEQwe6QVr_KA",
        "outputId": "5261807e-9f31-4249-e490-c3579041080b"
      },
      "source": [
        "pip install torch_scatter"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch_scatter\n",
            "  Downloading https://files.pythonhosted.org/packages/01/45/cd93ed3227248773ba8bc4b3beaa04e8bddb127a793a41bad875369951b3/torch_scatter-2.0.5.tar.gz\n",
            "Building wheels for collected packages: torch-scatter\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-scatter: filename=torch_scatter-2.0.5-cp36-cp36m-linux_x86_64.whl size=9481338 sha256=e0f165d56d428c26833d3f3cf77f06d4ba0045a8cfd565b1b04e533c5880fd95\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/59/d3/9866e4fd8e1fe9260740acfe22322c428bc0dc064d3ebc456c\n",
            "Successfully built torch-scatter\n",
            "Installing collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJzZGspVs8fQ",
        "outputId": "15791e05-4226-4134-f05a-042c3a8a66c4"
      },
      "source": [
        "pip install torch-scatter==latest+cu101 torch-sparse==latest+cu101 torch-cluster==latest+cu101 torch-spline-conv==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.7.0.html"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
            "Collecting torch-scatter==latest+cu101\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.7.0/torch_scatter-latest%2Bcu101-cp36-cp36m-linux_x86_64.whl (11.9MB)\n",
            "\u001b[K     |████████████████████████████████| 11.9MB 2.1MB/s \n",
            "\u001b[?25hCollecting torch-sparse==latest+cu101\n",
            "  Using cached https://pytorch-geometric.com/whl/torch-1.7.0/torch_sparse-latest%2Bcu101-cp36-cp36m-linux_x86_64.whl\n",
            "Collecting torch-cluster==latest+cu101\n",
            "  Using cached https://pytorch-geometric.com/whl/torch-1.7.0/torch_cluster-latest%2Bcu101-cp36-cp36m-linux_x86_64.whl\n",
            "Collecting torch-spline-conv==latest+cu101\n",
            "  Using cached https://pytorch-geometric.com/whl/torch-1.7.0/torch_spline_conv-latest%2Bcu101-cp36-cp36m-linux_x86_64.whl\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-sparse==latest+cu101) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy->torch-sparse==latest+cu101) (1.19.5)\n",
            "Installing collected packages: torch-scatter, torch-sparse, torch-cluster, torch-spline-conv\n",
            "  Found existing installation: torch-scatter 2.0.5\n",
            "    Uninstalling torch-scatter-2.0.5:\n",
            "      Successfully uninstalled torch-scatter-2.0.5\n",
            "  Found existing installation: torch-sparse 0.6.8\n",
            "    Uninstalling torch-sparse-0.6.8:\n",
            "      Successfully uninstalled torch-sparse-0.6.8\n",
            "  Found existing installation: torch-cluster 1.5.8\n",
            "    Uninstalling torch-cluster-1.5.8:\n",
            "      Successfully uninstalled torch-cluster-1.5.8\n",
            "  Found existing installation: torch-spline-conv 1.2.0\n",
            "    Uninstalling torch-spline-conv-1.2.0:\n",
            "      Successfully uninstalled torch-spline-conv-1.2.0\n",
            "Successfully installed torch-cluster-1.5.8 torch-scatter-2.0.5 torch-sparse-0.6.8 torch-spline-conv-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TK1INFGEpo_k"
      },
      "source": [
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.data import DataLoader\n",
        "from torch_geometric.datasets import TUDataset"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DA9xJNUctR-I"
      },
      "source": [
        "edge_index = torch.tensor([[0, 1],\n",
        "                           [1, 0],\n",
        "                           [1, 2],\n",
        "                           [2, 1]], dtype=torch.long)\n",
        "x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
        "\n",
        "data = Data(x=x, edge_index=edge_index.t().contiguous())"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "057mGxWMtsoP",
        "outputId": "cec19229-d1a9-462b-a4fd-31db055620a5"
      },
      "source": [
        "dataset = TUDataset(root='/tmp/ENZYMES', name='ENZYMES')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.chrsmrrs.com/graphkerneldatasets/ENZYMES.zip\n",
            "Extracting /tmp/ENZYMES/ENZYMES/ENZYMES.zip\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPG-3Fcnv_-k",
        "outputId": "e368d786-701f-4ec5-b860-1076c0c871aa"
      },
      "source": [
        "len(dataset)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "600"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaRaBse9wLcT",
        "outputId": "07551a30-d809-44af-a705-910fb18b7c32"
      },
      "source": [
        "dataset.num_classes"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyKmVwTbwN_o",
        "outputId": "bbc69d58-a284-4dc7-b60b-e57457ac6de5"
      },
      "source": [
        "dataset.num_node_features"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74X_HPe3wSVM",
        "outputId": "cd09ccdc-e357-415e-d0d8-24800d5412e6"
      },
      "source": [
        "data.is_undirected()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4if2EoPwXyN"
      },
      "source": [
        "train_dataset = dataset[:540]\n",
        "test_dataset = dataset[540:]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sq1bBc0kwwJV"
      },
      "source": [
        "loader = DataLoader(dataset, batch_size=32, shuffle=True)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z16oJvm6w4x8",
        "outputId": "2b9943cf-968d-4e49-b597-7d5872cc3214"
      },
      "source": [
        "from torch_geometric.datasets import Planetoid\n",
        "\n",
        "dataset = Planetoid(root='/tmp/Cora', name='Cora')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYOQ8ss1yQzG"
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
        "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1nb0u33yZrp"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = Net().to(device)\n",
        "data = dataset[0].to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "\n",
        "model.train()\n",
        "for epoch in range(200):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data)\n",
        "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqT-RUUnylY9",
        "outputId": "58cc9983-4c3b-4678-a6f1-176453ffbd23"
      },
      "source": [
        "model.eval()\n",
        "_, pred = model(data).max(dim=1)\n",
        "correct = int(pred[data.test_mask].eq(data.y[data.test_mask]).sum().item())\n",
        "acc = correct / int(data.test_mask.sum())\n",
        "print('Accuracy: {:.4f}'.format(acc))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8060\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}