{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import Batch\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.nn import TopKPooling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, SAGEConv\n",
    "from torch.nn import MSELoss, CrossEntropyLoss\n",
    "from torch_geometric.nn import GCNConv\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(999996, 7)\n"
     ]
    }
   ],
   "source": [
    "filehandler = open(\"../data/sample_data/hotel_reservation_sample.pkl\",\"rb\")\n",
    "dat = pickle.load(filehandler)\n",
    "filehandler.close()\n",
    "print(type(dat))\n",
    "print(dat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "global model\n",
    "model = \"\"\n",
    "num_features = 1\n",
    "num_classes = 6\n",
    "hc = 32\n",
    "n_epochs = 20\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dat.drop(columns = \"label\")\n",
    "y = dat.loc[:, \"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "train_dat = pd.DataFrame(X_train, columns = [\"0_frontend\", \"1_search\", \"2_geo\", \"3_rate\", \"4_profile\", \"5_locale\"])\n",
    "train_dat['label'] = y_train.to_list()\n",
    "test_dat = pd.DataFrame(X_test, columns = [\"0_frontend\", \"1_search\", \"2_geo\", \"3_rate\", \"4_profile\", \"5_locale\"])\n",
    "test_dat['label'] = y_test.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166666\n",
      "166666\n",
      "166666\n",
      "166666\n",
      "166666\n",
      "166666\n"
     ]
    }
   ],
   "source": [
    "X_train.shape\n",
    "print(len(y[y == 0]))\n",
    "print(len(y[y == 1]))\n",
    "print(len(y[y == 2]))\n",
    "print(len(y[y == 3]))\n",
    "print(len(y[y == 4]))\n",
    "print(len(y[y == 5]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n",
      "240000\n",
      "250000\n",
      "260000\n",
      "270000\n",
      "280000\n",
      "290000\n",
      "300000\n",
      "310000\n",
      "320000\n",
      "330000\n",
      "340000\n",
      "350000\n",
      "360000\n",
      "370000\n",
      "380000\n",
      "390000\n",
      "400000\n",
      "410000\n",
      "420000\n",
      "430000\n",
      "440000\n",
      "450000\n",
      "460000\n",
      "470000\n",
      "480000\n",
      "490000\n",
      "500000\n",
      "510000\n",
      "520000\n",
      "530000\n",
      "540000\n",
      "550000\n",
      "560000\n",
      "570000\n",
      "580000\n",
      "590000\n",
      "600000\n",
      "610000\n",
      "620000\n",
      "630000\n",
      "640000\n",
      "650000\n",
      "660000\n",
      "670000\n",
      "680000\n",
      "690000\n",
      "700000\n",
      "710000\n",
      "720000\n",
      "730000\n",
      "740000\n",
      "750000\n",
      "760000\n",
      "770000\n",
      "780000\n",
      "790000\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n"
     ]
    }
   ],
   "source": [
    "graphs_train = list()\n",
    "count = 0\n",
    "for row in train_dat.iterrows():\n",
    "    r = pd.Series(row)\n",
    "    r = r[1]\n",
    "    x = torch.tensor([[r['0_frontend']],\n",
    "                      [r['1_search']],\n",
    "                      [r['2_geo']],\n",
    "                      [r['3_rate']],\n",
    "                      [r['4_profile']],\n",
    "                      [r['5_locale']]] ,dtype = torch.float)\n",
    "    edge_index = torch.tensor([[0, 0, 1, 1, 4],\n",
    "                               [1, 4, 2, 3, 5]], dtype=torch.long)\n",
    "    if r['label'] == 0:\n",
    "        y = torch.tensor([1,0,0,0,0,0], dtype = torch.float)\n",
    "    elif r['label'] == 1:\n",
    "        y = torch.tensor([0,1,0,0,0,0], dtype = torch.float)\n",
    "    elif r['label'] == 2:\n",
    "        y = torch.tensor([0,0,1,0,0,0], dtype = torch.float)\n",
    "    elif r['label'] == 3:\n",
    "        y = torch.tensor([0,0,0,1,0,0], dtype = torch.float)\n",
    "    elif r['label'] == 4:\n",
    "        y = torch.tensor([0,0,0,0,1,0], dtype = torch.float)\n",
    "    elif r['label'] == 5:\n",
    "        y = torch.tensor([0,0,0,0,0,1], dtype = torch.float)\n",
    "    else:\n",
    "        print(\"unknown label encountered\")\n",
    "        break\n",
    "    graphs_train.append(Data(x = x, edge_index = edge_index,y = y))\n",
    "    count = count + 1\n",
    "    if count % 10000 == 0:\n",
    "        print(count)\n",
    "    \n",
    "count = 0\n",
    "graphs_test = list()\n",
    "for row in test_dat.iterrows():\n",
    "    r = pd.Series(row)\n",
    "    r = r[1]\n",
    "    x = torch.tensor([[r['0_frontend']],\n",
    "                      [r['1_search']],\n",
    "                      [r['2_geo']],\n",
    "                      [r['3_rate']],\n",
    "                      [r['4_profile']],\n",
    "                      [r['5_locale']]] ,dtype = torch.float)\n",
    "    edge_index = torch.tensor([[0, 0, 1, 1, 4],\n",
    "                               [1, 4, 2, 3, 5]], dtype=torch.long)\n",
    "    if r['label'] == 0:\n",
    "        y = torch.tensor([1,0,0,0,0,0], dtype = torch.float)\n",
    "    elif r['label'] == 1:\n",
    "        y = torch.tensor([0,1,0,0,0,0], dtype = torch.float)\n",
    "    elif r['label'] == 2:\n",
    "        y = torch.tensor([0,0,1,0,0,0], dtype = torch.float)\n",
    "    elif r['label'] == 3:\n",
    "        y = torch.tensor([0,0,0,1,0,0], dtype = torch.float)\n",
    "    elif r['label'] == 4:\n",
    "        y = torch.tensor([0,0,0,0,1,0], dtype = torch.float)\n",
    "    elif r['label'] == 5:\n",
    "        y = torch.tensor([0,0,0,0,0,1], dtype = torch.float)\n",
    "    else:\n",
    "        print(\"unknown label encountered\")\n",
    "        break\n",
    "    graphs_test.append(Data(x = x, edge_index = edge_index,y = y))\n",
    "    count = count + 1\n",
    "    if count % 10000 == 0:\n",
    "        print(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of graphs: 799996\n",
      "\n",
      "Data(edge_index=[2, 5], x=[6, 1], y=[6])\n",
      "===========================================================================================================\n",
      "Number of nodes: 6\n",
      "Number of edges: 5\n",
      "Average node degree: 0.83\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of graphs: {len(graphs_train)}')\n",
    "\n",
    "data = graphs_train[0]  # Get the first graph object.\n",
    "\n",
    "print()\n",
    "print(data)\n",
    "print('===========================================================================================================')\n",
    "\n",
    "# Gather some statistics about the graph.\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize scaling and dataloader\n",
    "\n",
    "scaler = StandardScaler()\n",
    "loader = DataLoader(graphs_train, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class GCN(torch.nn.Module):\n",
    "#     def __init__(self, hidden_channels):\n",
    "#         super(GCN, self).__init__()\n",
    "#         torch.manual_seed(12345)\n",
    "#         self.conv1 = GCNConv(num_features, hidden_channels)\n",
    "#         self.conv2 = GCNConv(hidden_channels, num_classes)\n",
    "\n",
    "#     def forward(self, data):\n",
    "#         x, edge_index = data.x, data.edge_index\n",
    "#         x = self.conv1(x, edge_index)\n",
    "#         x = x.relu()\n",
    "#         x = F.dropout(x, p=0.3, training=self.training)\n",
    "#         x = self.conv2(x, edge_index)\n",
    "# #         return F.softmax(x)\n",
    "#         return x\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = SAGEConv(num_features, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.1, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "#         return F.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(batch=[768], edge_index=[2, 640], x=[768, 1], y=[768])\n",
      "1\n",
      "799996\n",
      "6250\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "for d in range(1):\n",
    "    data = next(iter(loader))\n",
    "    data = data.to(device)\n",
    "    print(data)\n",
    "print(data.num_node_features)\n",
    "model = GCN(hidden_channels = hc).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "loss_func = CrossEntropyLoss()   \n",
    "\n",
    "print(len(graphs_train))\n",
    "print(len(loader))\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ongoing epoch is: 0\n",
      "Epoch: 000, Loss: 0.0283\n",
      "ongoing epoch is: 1\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for epoch in range(n_epochs):\n",
    "    print(\"ongoing epoch is:\", epoch)\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        count = count + 1\n",
    "        optimizer.zero_grad()                                                   \n",
    "        out = model(data) \n",
    "        loss = loss_func(out, data.y.long())\n",
    "        loss.backward()                                                         \n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pred = 0\n",
    "count_pred = 0\n",
    "count = 0\n",
    "for tg in graphs_test:\n",
    "    out = model(tg)\n",
    "    pred = out.argmax(dim=1)\n",
    "    if torch.all(torch.eq(tg.y, pred)):\n",
    "        num_pred += 1\n",
    "#         print(pred, tg.y)\n",
    "    count_pred +=1\n",
    "    count += 1\n",
    "\n",
    "    if count % 10000 == 0:\n",
    "        print(count)\n",
    "\n",
    "print(\"Accuracy: \", num_pred/count_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
